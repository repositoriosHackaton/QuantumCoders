{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1 align=\"center\">Proyecto Final - IntelliPrice</H1>\n",
    "<h3>Grupo: <i>Quantum Coders</i> - Chatbot Comparador de Productos</h3>\n",
    "Integrantes del grupo: Nikechi Camarena &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Aula: P02 - Panamá <br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Lucas Castillo<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Gabriel Cortez<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Sergio López<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;María Suira\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfded07",
   "metadata": {},
   "source": [
    "<H3>1. Se importan las librerias a utilizar.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3135945a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\slope\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\slope\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5f0d94",
   "metadata": {},
   "source": [
    "<H3>2. Se carga el dataset de precios y productos para las comparaciones.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06546142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precio</th>\n",
       "      <th>sucursal</th>\n",
       "      <th>id</th>\n",
       "      <th>marca</th>\n",
       "      <th>nombre</th>\n",
       "      <th>presentacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337.00</td>\n",
       "      <td>Sol y Mar</td>\n",
       "      <td>7798123131611</td>\n",
       "      <td>GREAT VALUE</td>\n",
       "      <td>Liquido Lavavajillas</td>\n",
       "      <td>500.0 cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>337.00</td>\n",
       "      <td>La Hacienda</td>\n",
       "      <td>7798123131611</td>\n",
       "      <td>GREAT VALUE</td>\n",
       "      <td>Liquido Lavavajillas</td>\n",
       "      <td>500.0 cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>279.00</td>\n",
       "      <td>El Refugio</td>\n",
       "      <td>7791172001348</td>\n",
       "      <td>DIAMANTE</td>\n",
       "      <td>Liquido Lavavajillas</td>\n",
       "      <td>500.0 ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>309.00</td>\n",
       "      <td>Las Margaritas</td>\n",
       "      <td>7791172001348</td>\n",
       "      <td>DIAMANTE</td>\n",
       "      <td>Liquido Lavavajillas</td>\n",
       "      <td>500.0 ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>319.99</td>\n",
       "      <td>El Retiro</td>\n",
       "      <td>8000580204906</td>\n",
       "      <td>FINISH</td>\n",
       "      <td>Liquido Lavavajillas</td>\n",
       "      <td>500.0 ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>38.50</td>\n",
       "      <td>Plaza del Mar</td>\n",
       "      <td>7791337001299</td>\n",
       "      <td>DANONINO</td>\n",
       "      <td>Yogurt</td>\n",
       "      <td>80.5 gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>43.40</td>\n",
       "      <td>Calle de las Flores</td>\n",
       "      <td>7791337001299</td>\n",
       "      <td>DANONINO</td>\n",
       "      <td>Yogurt</td>\n",
       "      <td>80.5 gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>42.40</td>\n",
       "      <td>El Rincón</td>\n",
       "      <td>7791337001299</td>\n",
       "      <td>DANONINO</td>\n",
       "      <td>Yogurt</td>\n",
       "      <td>80.5 gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>40.00</td>\n",
       "      <td>Gran Plaza</td>\n",
       "      <td>7791337001299</td>\n",
       "      <td>DANONINO</td>\n",
       "      <td>Yogurt</td>\n",
       "      <td>80.5 gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>43.00</td>\n",
       "      <td>Mercado del Sol</td>\n",
       "      <td>7791337001299</td>\n",
       "      <td>DANONINO</td>\n",
       "      <td>Yogurt</td>\n",
       "      <td>80.5 gr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     precio             sucursal             id        marca  \\\n",
       "0    337.00            Sol y Mar  7798123131611  GREAT VALUE   \n",
       "1    337.00          La Hacienda  7798123131611  GREAT VALUE   \n",
       "2    279.00           El Refugio  7791172001348     DIAMANTE   \n",
       "3    309.00       Las Margaritas  7791172001348     DIAMANTE   \n",
       "4    319.99            El Retiro  8000580204906       FINISH   \n",
       "..      ...                  ...            ...          ...   \n",
       "320   38.50        Plaza del Mar  7791337001299     DANONINO   \n",
       "321   43.40  Calle de las Flores  7791337001299     DANONINO   \n",
       "322   42.40            El Rincón  7791337001299     DANONINO   \n",
       "323   40.00           Gran Plaza  7791337001299     DANONINO   \n",
       "324   43.00      Mercado del Sol  7791337001299     DANONINO   \n",
       "\n",
       "                   nombre presentacion  \n",
       "0    Liquido Lavavajillas     500.0 cc  \n",
       "1    Liquido Lavavajillas     500.0 cc  \n",
       "2    Liquido Lavavajillas     500.0 ml  \n",
       "3    Liquido Lavavajillas     500.0 ml  \n",
       "4    Liquido Lavavajillas     500.0 ml  \n",
       "..                    ...          ...  \n",
       "320                Yogurt      80.5 gr  \n",
       "321                Yogurt      80.5 gr  \n",
       "322                Yogurt      80.5 gr  \n",
       "323                Yogurt      80.5 gr  \n",
       "324                Yogurt      80.5 gr  \n",
       "\n",
       "[325 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Unir los DataFrames en base al 'producto_id'\n",
    "df_productos = pd.read_csv(\"Lista_productos.csv\", delimiter=\";\")\n",
    "df_productos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f83d466",
   "metadata": {},
   "source": [
    "<H3>3. Se extraen los productos y sucursales para tener una lista con cada producto disponible en el Chatbot.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9b7a3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Liquido Lavavajillas', 'Aceite para bebe', 'Aceite de Canola',\n",
       "       'Café Instantaneo', 'Crema Dental', 'Crema Facial',\n",
       "       'Desinfectante', 'Enjuage Bucal', 'Escoba', 'Jabon de Baño',\n",
       "       'Lentejas', 'Mayonesa', 'Pan', 'Pañal', 'Shampoo', 'Vino Blanco',\n",
       "       'Yogurt'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_names = df_productos['nombre'].unique()\n",
    "print(product_names.size)\n",
    "product_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6066ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Sol y Mar', 'La Hacienda', 'El Refugio', 'Las Margaritas',\n",
       "       'El Retiro', 'La Sierra', 'El Manantial', 'El Pueblo',\n",
       "       'Avenida del Sol', 'Plaza del Mar', 'Calle de las Flores',\n",
       "       'Paseo de los Sueños', 'Boulevard de la Luna', 'El Rincón',\n",
       "       'Gran Plaza', 'Mercado del Sol', 'El Álamo', 'Gran Sur',\n",
       "       'La Estrella', 'La Fuente', 'Mercado Real', 'El Faro',\n",
       "       'Costa Azul', 'El Encanto', 'Brisa Marina', 'Las Colinas',\n",
       "       'Las Rocas', 'El Bosque', 'La Reserva', 'Monte Verde',\n",
       "       'El Horizonte', 'Primavera', 'La Casona', 'Los Laureles',\n",
       "       'El Paraíso', 'La Campiña', 'Vía Verde', 'Buenavista', 'La Senda',\n",
       "       'La Cumbre', 'El Triunfo', 'La Floresta', 'La Esperanza',\n",
       "       'El Campestre', 'Bella Vista', 'La Laguna', 'Campo Alegre',\n",
       "       'Las Fuentes', 'Valle Dorado', 'La Aurora'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch_name = df_productos['sucursal'].unique()\n",
    "print(branch_name.size)\n",
    "branch_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82da125e",
   "metadata": {},
   "source": [
    "<H3>4. Se cargan los datos de entrenamientos del intents.json y se hace el procesado de estos.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25a2e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Se cargan los Intents\n",
    "with open('intents.json') as file:\n",
    "    intents = json.load(file)\n",
    "\n",
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?', '!', '.', ',']\n",
    "\n",
    "\n",
    "# Procesamiento de Intents para el entrenamiento del modelo\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        words.extend(w)\n",
    "        documents.append((w, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "\n",
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "training = []\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "for doc in documents:\n",
    "    bag = []\n",
    "    pattern_words = doc[0]\n",
    "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "random.shuffle(training)\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "for i in training:\n",
    "    train_x.append(i[0])\n",
    "    train_y.append(i[1])\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "# Función para limpiar y lematizar oración\n",
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# Función para convertir oración a bolsa de palabras\n",
    "def bow(sentence, words, show_details=True):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = [0]*len(words)\n",
    "    for s in sentence_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == s:\n",
    "                bag[i] = 1\n",
    "    return(np.array(bag))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d289665",
   "metadata": {},
   "source": [
    "<H3>5. Se crea la clase que predecirá los inputs del usuario.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed1eb6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para predecir la clase con el modelo que se creará\n",
    "def predict_class(sentence, model):\n",
    "    p = bow(sentence, words, show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    \n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    print(return_list)\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80e8d3f",
   "metadata": {},
   "source": [
    "<H3>6. Se establecen las funciones para responder al usuario, haciendo busquedas en el dataframe creado.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f18d3191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener respuesta\n",
    "def get_response(ints, intents_json, msg):\n",
    "    \n",
    "    tag = ints[0]['intent']\n",
    "    print(tag)\n",
    "    list_of_intents = intents_json['intents']\n",
    "\n",
    "    if tag == 'products_list':\n",
    "        response = \"Estos son los productos disponibles:\\n\" + \"\\n\".join(product_names)\n",
    "        return response\n",
    "    elif tag == 'product_query':\n",
    "        product_name = get_product_name(msg)\n",
    "        prices = None\n",
    "        if product_name:\n",
    "            prices = get_product_prices(product_name)\n",
    "        if prices:\n",
    "            response = f\"Estos son los 10 precios más bajos que encontré para {product_name}:\\n\"\n",
    "            sorted_prices = sorted(prices, key=lambda x: x['precio'])[:10]\n",
    "            for price in sorted_prices:\n",
    "                response += \"- Sucursal {}: ${:.2f} - {}\\n\".format(price['sucursal'], price['precio'], price['presentacion'])\n",
    "            return response\n",
    "        else:\n",
    "            return \"Lo siento, no encontré ese producto. Podrías preguntar por la lista de productos disponibles.\"\n",
    "    elif tag == 'sucursales_disponibles':\n",
    "        response = \"Estas son las sucursales disponibles: \" + \"\\n\".join(branch_name)\n",
    "        return response\n",
    "    elif tag == 'productos_sucursal':\n",
    "        branch = get_branch_name(msg)\n",
    "        if branch:\n",
    "            product_branch = df_productos[df_productos['sucursal'] == branch]\n",
    "            response = f\"Los productos disponibles en la sucursal {branch} son:\\n\"\n",
    "            print(response)\n",
    "            for index, item in product_branch.iterrows():\n",
    "                response += \"- {} {} de {}\\n\".format(item['nombre'], item['marca'], item['presentacion'])\n",
    "            print(response)\n",
    "            return response\n",
    "        else:\n",
    "            return \"Esa sucursal no se encuentra en nuestra base de datos.\"\n",
    "\n",
    "    else:\n",
    "        for intent in intents['intents']:\n",
    "            if intent['tag'] == tag:\n",
    "                responses = intent['responses']\n",
    "        return random.choice(responses)    \n",
    "\n",
    "def get_product_prices(product_name):\n",
    "    result = df_productos[df_productos['nombre'].str.contains(product_name, case=False, na=False)]\n",
    "    if not result.empty:\n",
    "        return result[['sucursal', 'precio', 'marca', 'nombre', 'presentacion']].to_dict(orient='records')\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def normalizar_texto(texto):\n",
    "    # Eliminar acentos y caracteres especiales\n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "    # Eliminar signos de puntuación y caracteres especiales\n",
    "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
    "    return texto\n",
    "\n",
    "#Se implementan busquedas utilizando Operaciones de conjuntos\n",
    "\n",
    "def get_branch_name(frase):\n",
    "    frase_normalizada = normalizar_texto(frase.lower())\n",
    "    palabras_usuario = set(frase_normalizada.split())\n",
    "\n",
    "    for branch in branch_name:\n",
    "        b_normalizado = normalizar_texto(branch.lower())\n",
    "        palabras_branch = set(b_normalizado.split())\n",
    "        if palabras_branch.issubset(palabras_usuario):\n",
    "            return branch\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def get_product_name(frase):\n",
    "    frase_normalizada = normalizar_texto(frase.lower())\n",
    "    \n",
    "    palabras_usuario = set(frase_normalizada.split())\n",
    "    \n",
    "    for p in product_names:\n",
    "        p_normalizado = normalizar_texto(p.lower())\n",
    "        palabras_producto = set(p_normalizado.split())\n",
    "        if palabras_producto.issubset(palabras_usuario):\n",
    "            return p\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff18e564",
   "metadata": {},
   "source": [
    "<H3>7. Se crea una clase que contendrá el chatbot, su creación, entrenamiento y funcionamiento.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8289dce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\slope\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\slope\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0498 - loss: 2.4980  \n",
      "0.06060606241226196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\slope\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'SGD', because it has 2 variables whereas the saved optimizer has 8 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self):\n",
    "        self.model = self.create_model()\n",
    "        self.train_model()\n",
    "        self.intents = intents\n",
    "\n",
    "    def create_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "        sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "        loss, accuracy = model.evaluate(train_x, train_y)\n",
    "        print(accuracy)\n",
    "        return model\n",
    "\n",
    "    def train_model(self):\n",
    "        try:\n",
    "            self.model.load_weights(\"model.weights.h5\")\n",
    "        except:\n",
    "            self.model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n",
    "            self.model.save_weights(\"model.weights.h5\")\n",
    "\n",
    "\n",
    "    def chat(self, sentence):\n",
    "        ints = predict_class(sentence, self.model)\n",
    "        res = get_response(ints, self.intents, sentence)\n",
    "        return res\n",
    "\n",
    "\n",
    "chatbot = Chatbot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b20142",
   "metadata": {},
   "source": [
    "<H3>8. Se crea la interfaz gráfica del Chatbot.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "578bf572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "[{'intent': 'greeting', 'probability': '0.9992493'}]\n",
      "greeting\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "[{'intent': 'product_query', 'probability': '0.92388886'}]\n",
      "product_query\n"
     ]
    }
   ],
   "source": [
    "class ChatGUI:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.window = tk.Tk()\n",
    "        self.window.title(\"IntelliPrice Chatbot\")\n",
    "\n",
    "        # Mejorar nitidez del texto en Windows\n",
    "        try:\n",
    "            from ctypes import windll\n",
    "            windll.shcore.SetProcessDpiAwareness(1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Configurar colores y fuentes\n",
    "        self.app_bg_color = \"#e0e0e0\"  # Color de fondo de la aplicación (gris claro)\n",
    "        self.text_bg_color = \"#f0f0f0\"  # Color de fondo del cuadro de texto (gris un poco más oscuro)\n",
    "        self.text_color = \"#333333\"  # Color de texto\n",
    "        self.entry_bg_color = \"#ffffff\"  # Color de fondo de la entrada\n",
    "        self.button_bg_color = \"#1428a0\"  # Color de fondo del botón\n",
    "        self.button_text_color = \"#ffffff\"  # Color de texto del botón\n",
    "        self.title_bg_color = \"#1428a0\"  # Color de fondo del título\n",
    "        self.title_text_color = \"#ffffff\"  # Color de texto del título\n",
    "        self.font = (\"Arial\", 16)\n",
    "        self.entry_font = (\"Arial\", 14)\n",
    "        self.button_font = (\"Arial\", 14, \"bold\")\n",
    "        self.title_font = (\"Arial\", 26, \"bold\")\n",
    "        \n",
    "\n",
    "        self.window.config(bg=self.app_bg_color)\n",
    "\n",
    "        # Añadir título\n",
    "        self.title_frame = Frame(self.window, bg=self.title_bg_color)\n",
    "        self.title_frame.pack(fill=tk.X)\n",
    "        self.title_label = tk.Label(self.title_frame, text=\"Bienvenido a IntelliPrice\", bg=self.title_bg_color, fg=self.title_text_color, font=self.title_font, pady=10)\n",
    "        self.title_label.pack(pady=10)\n",
    "\n",
    "        self.cta_label = tk.Label(self.window, text=\"¡Descubre dónde ahorrar más en tus compras!\", bg=self.app_bg_color, fg=\"#000000\", font=(\"Arial\", 16))\n",
    "        self.cta_label.pack(pady=10)\n",
    "\n",
    "        self.chat_frame = Frame(self.window, bg=self.text_bg_color)\n",
    "        self.chat_frame.pack(padx=10, pady=10)\n",
    "\n",
    "        self.text_widget = Text(self.chat_frame, width=60, height=20, bg=self.text_bg_color, fg=self.text_color, font=self.font, wrap=\"word\", relief=\"flat\", bd=0)\n",
    "        self.text_widget.pack(side=LEFT, padx=10, pady=10)\n",
    "        self.text_widget.config(state=DISABLED)\n",
    "\n",
    "        self.scrollbar = Scrollbar(self.chat_frame)\n",
    "        self.scrollbar.pack(side=RIGHT, fill=Y)\n",
    "        self.text_widget.config(yscrollcommand=self.scrollbar.set)\n",
    "        self.scrollbar.config(command=self.text_widget.yview)\n",
    "\n",
    "        self.entry = Entry(self.window, width=55, bg=self.entry_bg_color, fg=self.text_color, font=self.entry_font, insertbackground=self.text_color, relief=\"flat\", bd=1)\n",
    "        self.entry.pack(padx=10, pady=10)\n",
    "        self.entry.bind(\"<Return>\", self.send_message)\n",
    "\n",
    "        self.send_button = Button(self.window, text=\"Enviar\", command=self.send_message, bg=self.button_bg_color, fg=self.button_text_color, font=self.button_font, bd=0, padx=10, pady=5)\n",
    "        self.send_button.pack(pady=10)\n",
    "\n",
    "\n",
    "        \n",
    "    def send_message(self, event=None):\n",
    "        message = self.entry.get()\n",
    "        self.entry.delete(0, END)\n",
    "        \n",
    "        if message:\n",
    "            self.display_user_message(f\"{message}\\n\")\n",
    "            response = chatbot.chat(message) \n",
    "            self.display_bot_message(f\"{response}\\n\")\n",
    "\n",
    "    def display_user_message(self, message):\n",
    "        self.text_widget.tag_configure(\"black\", foreground=\"#000000\", font=(\"Arial\", 16, \"bold\"))\n",
    "        self.text_widget.config(state=NORMAL)\n",
    "        self.text_widget.insert(END, \"Tu: \", \"black\")\n",
    "        self.text_widget.insert(END, message)\n",
    "        self.text_widget.config(state=DISABLED)\n",
    "        self.text_widget.yview(END)\n",
    "\n",
    "    def display_bot_message(self, message):\n",
    "        self.text_widget.tag_configure(\"blue\", foreground=\"#1428a0\", font=(\"Arial\", 16, \"bold\"))\n",
    "        self.text_widget.config(state=NORMAL)\n",
    "        self.text_widget.insert(END, \"Bot: \", \"blue\")\n",
    "        self.text_widget.insert(END, message)\n",
    "        self.text_widget.config(state=DISABLED)\n",
    "        self.text_widget.yview(END)\n",
    "\n",
    "    def run(self):\n",
    "        self.window.mainloop()\n",
    "\n",
    "chat_gui = ChatGUI()\n",
    "chat_gui.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
